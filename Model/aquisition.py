# -*- coding: utf-8 -*-
"""Aquisition

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1iWLGZm5QnkNSheQQcMubkePAXJUK60Pu
"""

import cv2
import os
import numpy as np

"""Reading videos and extracting frames"""

# Cross hands in fron action 40 Reading the data.

X_40 = []
n=7
k=0
listing_videos = os.listdir('/content/drive/My Drive/New_dataset/Cross hands in front_action40')

for vid in listing_videos:
  print('Video nb ',k ,' :',vid)

  videoFile = '/content/drive/My Drive/New_dataset/Cross hands in front_action40/'+vid

  cap = cv2.VideoCapture(videoFile)

  total_frames = cap.get(cv2.CAP_PROP_FRAME_COUNT)
  print("total frames :", total_frames)

  frames_step = total_frames//n
  print("Frames step :",frames_step)
  frames = []
  for i in range(n):
        #here, we set the parameter 1 which is the frame number to the frame (i*frames_step)
    cap.set(1,i*frames_step)
    ret, frame = cap.read()

    # resize image
    scale_percent = 10 # percent of original size
    width = int(frame.shape[1] * scale_percent / 100)
    height = int(frame.shape[0] * scale_percent / 100)
    dim = (width, height)
    resized = cv2.resize(frame, dim, interpolation = cv2.INTER_AREA)
    img = cv2.cvtColor(resized, cv2.COLOR_BGR2RGB)
    
    frames.append(img)
  k = k + 1  
    
  X_40.append(frames)

# Hand waving action 23 Reading the data.

X_23 = []
n=7
k=0
listing_videos = os.listdir('/content/drive/My Drive/New_dataset/Hand waving_action23')

for vid in listing_videos:
  print('Video nb ',k ,' :',vid)

  videoFile = '/content/drive/My Drive/New_dataset/Hand waving_action23/'+vid

  cap = cv2.VideoCapture(videoFile)

  total_frames = cap.get(cv2.CAP_PROP_FRAME_COUNT)
  print("total frames :", total_frames)

  frames_step = total_frames//n
  print("Frames step :",frames_step)
  frames = []
  for i in range(n):
        #here, we set the parameter 1 which is the frame number to the frame (i*frames_step)
    cap.set(1,i*frames_step)
    ret, frame = cap.read()

    # resize image
    scale_percent = 10 # percent of original size
    width = int(frame.shape[1] * scale_percent / 100)
    height = int(frame.shape[0] * scale_percent / 100)
    dim = (width, height)
    resized = cv2.resize(frame, dim, interpolation = cv2.INTER_AREA)
    img = cv2.cvtColor(resized, cv2.COLOR_BGR2RGB)
    
    frames.append(img)
  k = k + 1  
    
  X_23.append(frames)

# Pointing action 31 Reading the data.

X_31 = []
n=7
k=0
listing_videos = os.listdir('/content/drive/My Drive/New_dataset/Pointing_action31')

for vid in listing_videos:
  print('Video nb ',k ,' :',vid)

  videoFile = '/content/drive/My Drive/New_dataset/Pointing_action31/'+vid

  cap = cv2.VideoCapture(videoFile)

  total_frames = cap.get(cv2.CAP_PROP_FRAME_COUNT)
  print("total frames :", total_frames)

  frames_step = total_frames//n
  print("Frames step :",frames_step)
  frames = []
  for i in range(n):
        #here, we set the parameter 1 which is the frame number to the frame (i*frames_step)
    cap.set(1,i*frames_step)
    ret, frame = cap.read()

    # resize image
    scale_percent = 10 # percent of original size
    width = int(frame.shape[1] * scale_percent / 100)
    height = int(frame.shape[0] * scale_percent / 100)
    dim = (width, height)
    resized = cv2.resize(frame, dim, interpolation = cv2.INTER_AREA)
    img = cv2.cvtColor(resized, cv2.COLOR_BGR2RGB)
    
    frames.append(img)
  k = k + 1  
    
  X_31.append(frames)

# Shake head action 36 Reading the data.

X_36 = []
n=7
k=0
listing_videos = os.listdir('/content/drive/My Drive/New_dataset/Shake head_action36')

for vid in listing_videos:
  print('Video nb ',k ,' :',vid)

  videoFile = '/content/drive/My Drive/New_dataset/Shake head_action36/'+vid

  cap = cv2.VideoCapture(videoFile)

  total_frames = cap.get(cv2.CAP_PROP_FRAME_COUNT)
  print("total frames :", total_frames)

  frames_step = total_frames//n
  print("Frames step :",frames_step)
  frames = []
  for i in range(n):
        #here, we set the parameter 1 which is the frame number to the frame (i*frames_step)
    cap.set(1,i*frames_step)
    ret, frame = cap.read()

    # resize image
    scale_percent = 10 # percent of original size
    width = int(frame.shape[1] * scale_percent / 100)
    height = int(frame.shape[0] * scale_percent / 100)
    dim = (width, height)
    resized = cv2.resize(frame, dim, interpolation = cv2.INTER_AREA)
    img = cv2.cvtColor(resized, cv2.COLOR_BGR2RGB)
    
    frames.append(img)
  k = k + 1  
    
  X_36.append(frames)

"""Converting data to arrays and saving them"""

X_40_arr = np.array(X_40)
X_23_arr = np.array(X_23)
X_31_arr = np.array(X_31)
X_36_arr = np.array(X_36)

with open('X_40_arr.npy', 'wb') as f:

    np.save(f, X_40_arr)

"""
with open('test.npy', 'rb') as f:

    a = np.load(f)
"""

with open('X_23_arr.npy', 'wb') as f:

    np.save(f, X_23_arr)

with open('X_31_arr.npy', 'wb') as f:

    np.save(f, X_31_arr)

with open('X_36_arr.npy', 'wb') as f:

    np.save(f, X_36_arr)